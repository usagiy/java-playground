
blocking-dispatcher{
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    // in Akka previous to 2.4.2:
    core-pool-size-min = 16
    core-pool-size-max = 16
    max-pool-size-min = 16
    max-pool-size-max = 16
    // or in Akka 2.4.2+
    fixed-pool-size = 16
  }
  throughput = 100
}




#zbog greske
#akka.http.scaladsl.model.IllegalResponseException: Response reason phrase exceeds the configured limit of 64 characters

akka.http.client.parsing {
  max-response-reason-length = 512
}



#keystore
akka.ssl-config {
    
    trustManager = {
      stores = [
        { path: "E:\\TEMP\\keystore.jks", type: "JKS" }
      ]
  	}
    
    keyManager = {
      stores = [
        {
          type: "jks",
          path: "E:\\TEMP\\keystore.jks",
          password: "changeme"
        },
      ]
    }
}


# Kamon Metrics
# ~~~~~~~~~~~~~~

kamon {

  metric {

    # Time interval for collecting all metrics and send the snapshots to all subscribed actors.
    tick-interval = 10 seconds

    # Disables a big error message that will be typically logged if your application wasn't started
    # with the -javaagent:/path-to-aspectj-weaver.jar option. If you are only using KamonStandalone
    # it might be ok for you to turn this error off.
    disable-aspectj-weaver-missing-error = false

    # Specify if entities that do not match any include/exclude filter should be tracked.
    track-unmatched-entities = yes

    filters {
      akka-actor {
        includes = ["**"]
        #excludes = []
        #includes = ["*/user/*"]
        #excludes = [ "*/system/**", "*/user/IO-**", "*kamon*" ]
        #includes = ["*/device-manager-actor/*"]
        #excludes = [ "*/system/**", "*/user/StreamSupervisor**", "kamon**", "/kamon*" ]
      }

      akka-router {
        includes = ["*/user/*"]
        excludes = []
      }

      akka-dispatcher {
        #includes = ["*/user/*"]
        includes = ["**"]
        excludes = []
      }

      trace {
        includes = [ "**" ]
        excludes = [ ]
      }
    }
  }

  # Controls whether the AspectJ Weaver missing warning should be displayed if any Kamon module requiring AspectJ is
  # found in the classpath but the application is started without the AspectJ Weaver.
  show-aspectj-missing-warning = yes

  statsd {

    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
    #hostname = "127.0.0.1"
    #hostname = "192.168.99.100"
    
    #porta nema
    port = 8125
    
    hostname = "10.255.0.47"    
	

    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
    # kamon.metric.tick-interval setting.
    flush-interval = 10 seconds

    # Max packet size for UDP metrics data sent to StatsD.
    max-packet-size = 1024 bytes

    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
    subscriptions {
      histogram       = [ "**" ]
      min-max-counter = [ "**" ]
      gauge           = [ "**" ]
      counter         = [ "**" ]
      trace           = [ "**" ]
      trace-segment   = [ "**" ]
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
      system-metric   = [ "**" ]
      http-server     = [ "**" ]
    }

    # FQCN of the implementation of `kamon.statsd.MetricKeyGenerator` to be instantiated and used for assigning
    # metric names. The implementation must have a single parameter constructor accepting a `com.typesafe.config.Config`.
    metric-key-generator = kamon.statsd.SimpleMetricKeyGenerator

    simple-metric-key-generator {

      # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
      # this pattern:
      #    application.host.entity.entity-name.metric-name
      application = "yourapp"

      # Includes the name of the hostname in the generated metric. When set to false, the scheme for the metrics
      # will look as follows:
      #    application.entity.entity-name.metric-name
      include-hostname = true

      # Allow users to override the name of the hostname reported by kamon. When changed, the scheme for the metrics
      # will have the following pattern:
      #   application.hostname-override-value.entity.entity-name.metric-name
      hostname-override = none

      # When the sections that make up the metric names have special characters like dots (very common in dispatcher
      # names) or forward slashes (all actor metrics) we need to sanitize those values before sending them to StatsD
      # with one of the following strategies:
      #   - normalize: changes ': ' to '-' and ' ', '/' and '.' to '_'.
      #   - percent-encode: percent encode the section on the metric name. Please note that StatsD doesn't support
      #     percent encoded metric names, this option is only useful if using our docker image which has a patched
      #     version of StatsD or if you are running your own, customized version of StatsD that supports this.
      metric-name-normalization-strategy = normalize
    }
  }
  
  
 jmx {
 
  subscriptions {
      histogram       = [ "**" ]
      min-max-counter = [ "**" ]
      gauge           = [ "**" ]
      counter         = [ "**" ]
      trace           = [ "**" ]
      trace-segment   = [ "**" ]
      akka-actor      = [ "**" ]
      akka-dispatcher = [ "**" ]
      akka-router     = [ "**" ]
      system-metric   = [ "**" ]
      http-server     = [ "**" ]
      kamon-mxbeans   = [ "**" ]
    }
  }
  

 influxdb {
  subscriptions {
    histogram       = [ "**" ]
    min-max-counter = [ "**" ]
    gauge           = [ "**" ]
    counter         = [ "**" ]
    trace           = [ "**" ]
    trace-segment   = [ "**" ]
    akka-actor      = [ "**" ]
    akka-dispatcher = [ "**" ]
    akka-router     = [ "**" ]
    system-metric   = [ "**" ]
    http-server     = [ "**" ]
  }
  
  hostname = "10.255.0.20"    
  port = 8086
  database = "dm_test"
  protocol = "http"

  application-name = "device-manager"
  hostname-override = none
  #percentiles = [50.0, 70.5]
  
}
  
   # Configuring what JMX metrics to export to Kamon
  kamon-mxbeans {
    mbeans = [
      { "name": "my-mbean", "jmxQuery": "test:type=exampleBean,name=*",
        "attributes": [
      { "name": "Value1", "type": "counter" },
      { "name": "Value2", "type": "counter" } ] }
    ],
    identify-delay-interval-ms = 1000,
    identify-interval-ms = 1000,
    value-check-interval-ms = 1000
  }

  # modules can be disabled at startup using yes/no arguments.
  modules {
    kamon-log-reporter.auto-start = yes
    kamon-system-metrics.auto-start = yes
    kamon-influxdb.auto-start = no
    kamon-statsd.auto-start = no
    kamon-akka.auto-start = yes
    kamon-mxbeans {
      auto-start = yes
      requires-aspectj = no
      extension-class = "kamon.jmx.extension.JMXMetricImporter"
    }
  }

}


# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout. 
akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 100
  
  # How long to wait for `KafkaProducer.close`
  close-timeout = 60s
  
  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}
  

# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout. 
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms
  
  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that blocking of the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms
  
  # The stage will be await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s
  
  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s
  
  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `TimeoutException`.
  commit-timeout = 15s
  
  # If the KafkaConsumer can't connect to the broker the poll will be
  # aborted after this timeout. The KafkaConsumerActor will throw
  # org.apache.kafka.common.errors.WakeupException which will be ignored
  # until max-wakeups limit gets exceeded.
  wakeup-timeout = 3s

  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
  max-wakeups = 10
  
  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    # Disable auto-commit by default
    enable.auto.commit = false
  }
}
  
  




